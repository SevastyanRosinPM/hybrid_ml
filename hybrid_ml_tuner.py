import numpy as np
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.datasets import load_wine
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import time
import matplotlib.pyplot as plt
from pymoo.algorithms.moo.nsga2 import NSGA2
from pymoo.core.problem import Problem
from pymoo.optimize import minimize
from pymoo.operators.crossover.sbx import SBX
from pymoo.operators.mutation.pm import PM
from pymoo.operators.sampling.rnd import IntegerRandomSampling
import warnings
warnings.filterwarnings('ignore')

# –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
data = load_wine()
X, y = data.data, data.target

# –ú–ê–°–®–¢–ê–ë–ò–†–û–í–ê–ù–ò–ï –î–ê–ù–ù–´–•
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

print("=" * 80)
print("–ò–ï–†–ê–†–•–ò–ß–ï–°–ö–ê–Ø –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø ML-–ú–û–î–ï–õ–ï–ô")
print("=" * 80)
print("‚úÖ –î–∞–Ω–Ω—ã–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω—ã –¥–ª—è SVM –∏ LogisticRegression")
print("‚úÖ –£–≤–µ–ª–∏—á–µ–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π –¥–ª—è LogisticRegression")
print("‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –æ–±—É—á–µ–Ω–∏—è")

# –°–ª–æ–≤–∞—Ä—å –º–æ–¥–µ–ª–µ–π —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
MODELS = {
    0: {'name': 'RandomForest', 'class': RandomForestClassifier, 'params': ['n_estimators', 'max_depth']},
    1: {'name': 'GradientBoosting', 'class': GradientBoostingClassifier, 'params': ['n_estimators', 'learning_rate']},
    2: {'name': 'SVM', 'class': SVC, 'params': ['C', 'gamma']},
    3: {'name': 'LogisticRegression', 'class': LogisticRegression, 'params': ['C', 'max_iter']}
}

class ImprovedHierarchicalMLOptimization(Problem):
    def __init__(self, X_train, y_train, X_val, y_val):
        self.X_train = X_train
        self.y_train = y_train  
        self.X_val = X_val
        self.y_val = y_val
        self.history = []
        self.failed_evaluations = 0
        
        # n_var: 3 –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ [model_type, param1, param2]
        super().__init__(n_var=3, 
                        n_obj=3, 
                        xl=np.array([0, 1, 1]),    # [model_type, param1, param2] 
                        xu=np.array([len(MODELS)-1, 200, 100]), 
                        vtype=int)

    def _create_model(self, model_type, param1, param2):
        """–°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏"""
        model_info = MODELS[model_type]
        model_name = model_info['name']
        
        if model_name == 'RandomForest':
            return RandomForestClassifier(
                n_estimators=param1, 
                max_depth=param2 if param2 > 1 else None,
                random_state=42
            )
        elif model_name == 'GradientBoosting':
            return GradientBoostingClassifier(
                n_estimators=param1,
                learning_rate=param2 / 100.0,  # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º learning_rate
                random_state=42
            )
        elif model_name == 'SVM':
            return SVC(
                C=param1 / 10.0,  # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º C
                gamma=param2 / 100.0,  # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º gamma
                random_state=42
            )
        elif model_name == 'LogisticRegression':
            return LogisticRegression(
                C=param1 / 10.0,  # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º C
                max_iter=1000,
                random_state=42,
                solver='liblinear'
            )

    def _evaluate(self, x, out, *args, **kwargs):
        objectives = []
        
        for i in range(len(x)):
            model_type = int(x[i, 0])
            param1 = int(x[i, 1])
            param2 = int(x[i, 2])
            
            model_info = MODELS[model_type]
            model_name = model_info['name']
            
            try:
                # –°–û–ó–î–ê–ï–ú –ò –û–ë–£–ß–ê–ï–ú –ú–û–î–ï–õ–¨
                start_time = time.time()
                model = self._create_model(model_type, param1, param2)
                model.fit(self.X_train, self.y_train)
                accuracy = model.score(self.X_val, self.y_val)
                training_time = time.time() - start_time
                
                # –°–ª–æ–∂–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏
                if model_name in ['RandomForest', 'GradientBoosting']:
                    complexity = param1 * 10
                elif model_name == 'SVM':
                    complexity = param1 * 3
                else:
                    complexity = param1 * 2
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
                self.history.append({
                    'model_type': model_type,
                    'model_name': model_name,
                    'param1': param1,
                    'param2': param2,
                    'accuracy': accuracy,
                    'training_time': training_time,
                    'complexity': complexity
                })
                
                objectives.append([-accuracy, training_time, complexity])
                
            except Exception as e:
                # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–∏–ª–∞—Å—å, –Ω–∞–∑–Ω–∞—á–∞–µ–º –ø–ª–æ—Ö–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
                self.failed_evaluations += 1
                objectives.append([0, 1000, 1000])
        
        out["F"] = np.array(objectives)


print("üöÄ –ó–ê–ü–£–°–ö –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò...")
problem = ImprovedHierarchicalMLOptimization(X_train, y_train, X_val, y_val)

algorithm = NSGA2(
    pop_size=25,
    sampling=IntegerRandomSampling(),
    crossover=SBX(prob=0.9, eta=15),
    mutation=PM(prob=0.1, eta=20),
    eliminate_duplicates=True
)

print("–ü–æ–∏—Å–∫ –ü–∞—Ä–µ—Ç–æ-–æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π...")
res = minimize(problem, algorithm, ('n_gen', 30), verbose=False)

print(f"‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
print(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(res.X)} —Ä–µ—à–µ–Ω–∏–π")
print(f"‚ùå –ù–µ—É–¥–∞—á–Ω—ã—Ö –æ–±—É—á–µ–Ω–∏–π: {problem.failed_evaluations}")

# –û–ë–†–ê–ë–û–¢–ö–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í
def process_improved_results(res, problem):
    results = []
    for i in range(len(res.X)):
        model_type = int(res.X[i, 0])
        param1 = int(res.X[i, 1])
        param2 = int(res.X[i, 2])
        
        model_info = MODELS[model_type]
        
        accuracy = -res.F[i, 0]
        training_time = res.F[i, 1]
        complexity = res.F[i, 2]
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ—É–¥–∞—á–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è
        if accuracy <= 0 or training_time >= 1000:
            continue
            
        results.append({
            'model_type': model_type,
            'model_name': model_info['name'],
            'param1': param1,
            'param2': param2,
            'accuracy': accuracy,
            'training_time': training_time,
            'complexity': complexity
        })
    return results

pareto_results = process_improved_results(res, problem)

print(f"üìà –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π: {len(pareto_results)}")

# –í–´–í–û–î –†–ï–ó–£–õ–¨–¢–ê–¢–û–í
print("\n" + "=" * 80)
print("–¢–û–ü-10 –ü–ê–†–ï–¢–û-–û–ü–¢–ò–ú–ê–õ–¨–ù–´–• –†–ï–®–ï–ù–ò–ô")
print("=" * 80)
print("–ú–æ–¥–µ–ª—å           | –ü–∞—Ä–∞–º–µ—Ç—Ä—ã          | Accuracy | Time(sec) | Complexity")
print("-" * 80)

if pareto_results:
    top_solutions = sorted(pareto_results, key=lambda x: x['accuracy'], reverse=True)[:10]
    
    for i, sol in enumerate(top_solutions, 1):
        if sol['model_name'] == 'RandomForest':
            params = f"n_est={sol['param1']}, max_d={sol['param2']}"
        elif sol['model_name'] == 'GradientBoosting':
            params = f"n_est={sol['param1']}, lr={sol['param2']/100:.3f}"
        elif sol['model_name'] == 'SVM':
            params = f"C={sol['param1']/10:.1f}, gamma={sol['param2']/100:.3f}"
        else:
            params = f"C={sol['param1']/10:.1f}, iter=1000"
        
        print(f"{sol['model_name']:15} | {params:18} | {sol['accuracy']:8.3f} | {sol['training_time']:9.3f} | {sol['complexity']:10}")
else:
    print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É–≤–µ–ª–∏—á–∏—Ç—å –ø–æ–ø—É–ª—è—Ü–∏—é.")

# –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø
if pareto_results:
    print("\n" + "=" * 80)
    print("–°–†–ê–í–ù–ò–¢–ï–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –ú–û–î–ï–õ–ï–ô")
    print("=" * 80)

    fig, axes = plt.subplots(2, 2, figsize=(15, 12))

    # –¶–≤–µ—Ç–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –º–æ–¥–µ–ª–µ–π
    colors = {'RandomForest': 'red', 'GradientBoosting': 'blue', 
              'SVM': 'green', 'LogisticRegression': 'orange'}

    # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ —Ç–∏–ø–∞–º –º–æ–¥–µ–ª–µ–π
    model_groups = {}
    for sol in pareto_results:
        model_name = sol['model_name']
        if model_name not in model_groups:
            model_groups[model_name] = []
        model_groups[model_name].append(sol)

    # –ì—Ä–∞—Ñ–∏–∫ 1: Accuracy vs Training Time
    for model_name, solutions in model_groups.items():
        accuracies = [s['accuracy'] for s in solutions]
        times = [s['training_time'] for s in solutions]
        axes[0, 0].scatter(times, accuracies, c=colors[model_name], 
                          label=model_name, s=80, alpha=0.7)

    axes[0, 0].set_xlabel('–í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è (—Å–µ–∫)')
    axes[0, 0].set_ylabel('–¢–æ—á–Ω–æ—Å—Ç—å (Accuracy)')
    axes[0, 0].set_title('Accuracy vs Training Time\n(–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π)')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)

    # –ì—Ä–∞—Ñ–∏–∫ 2: –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø–æ –º–æ–¥–µ–ª—è–º
    if model_groups:
        model_names = list(model_groups.keys())
        accuracies_by_model = [[s['accuracy'] for s in model_groups[model]] 
                              for model in model_names]

        box_plot = axes[0, 1].boxplot(accuracies_by_model, labels=model_names, 
                                     patch_artist=True)
        for patch, color in zip(box_plot['boxes'], [colors[model] for model in model_names]):
            patch.set_facecolor(color)

        axes[0, 1].set_ylabel('–¢–æ—á–Ω–æ—Å—Ç—å (Accuracy)')
        axes[0, 1].set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø–æ —Ç–∏–ø–∞–º –º–æ–¥–µ–ª–µ–π')
        axes[0, 1].grid(True, alpha=0.3)

    # –ì—Ä–∞—Ñ–∏–∫ 3: –õ—É—á—à–∏–µ –º–æ–¥–µ–ª–∏ –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º
    if model_groups:
        models = list(model_groups.keys())
        best_accuracy = [max(model_groups[model], key=lambda x: x['accuracy'])['accuracy'] 
                        for model in models]
        best_time = [min(model_groups[model], key=lambda x: x['training_time'])['training_time'] 
                    for model in models]

        x = np.arange(len(models))
        width = 0.35

        axes[1, 0].bar(x - width/2, best_accuracy, width, label='–ú–∞–∫—Å. —Ç–æ—á–Ω–æ—Å—Ç—å', alpha=0.8)
        axes[1, 0].bar(x + width/2, best_time, width, label='–ú–∏–Ω. –≤—Ä–µ–º—è', alpha=0.8)
        axes[1, 0].set_xlabel('–¢–∏–ø –º–æ–¥–µ–ª–∏')
        axes[1, 0].set_ylabel('–ó–Ω–∞—á–µ–Ω–∏—è')
        axes[1, 0].set_title('–õ—É—á—à–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –ø–æ —Ç–∏–ø–∞–º –º–æ–¥–µ–ª–µ–π')
        axes[1, 0].set_xticks(x)
        axes[1, 0].set_xticklabels(models)
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)

    # –ì—Ä–∞—Ñ–∏–∫ 4: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ—à–µ–Ω–∏–π –ø–æ –º–æ–¥–µ–ª—è–º
    model_counts = {model: len(solutions) for model, solutions in model_groups.items()}
    axes[1, 1].bar(model_counts.keys(), model_counts.values(), 
                  color=[colors[model] for model in model_counts.keys()], alpha=0.7)
    axes[1, 1].set_xlabel('–¢–∏–ø –º–æ–¥–µ–ª–∏')
    axes[1, 1].set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ—à–µ–Ω–∏–π –≤ –ü–∞—Ä–µ—Ç–æ-—Ñ—Ä–æ–Ω—Ç–µ')
    axes[1, 1].set_title('–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π –≤ –ü–∞—Ä–µ—Ç–æ-—Ñ—Ä–æ–Ω—Ç–µ')
    for i, count in enumerate(model_counts.values()):
        axes[1, 1].text(i, count + 0.1, str(count), ha='center')

    plt.tight_layout()
    plt.show()

    # –°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó
    print("\n" + "=" * 80)
    print("–°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
    print("=" * 80)

    for model_name, solutions in model_groups.items():
        accuracies = [s['accuracy'] for s in solutions]
        times = [s['training_time'] for s in solutions]
        
        print(f"\n{model_name}:")
        print(f"  –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤ –ü–∞—Ä–µ—Ç–æ-—Ñ—Ä–æ–Ω—Ç–µ: {len(solutions)}")
        print(f"  –õ—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {max(accuracies):.3f}")
        print(f"  –°—Ä–µ–¥–Ω—è—è —Ç–æ—á–Ω–æ—Å—Ç—å: {np.mean(accuracies):.3f}")
        print(f"  –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è: {min(times):.3f} —Å–µ–∫")
        print(f"  –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {np.mean(times):.3f} —Å–µ–∫")

print("\n" + "=" * 80)
print("üéØ AHP + TOPSIS –î–õ–Ø –§–ò–ù–ê–õ–¨–ù–û–ì–û –í–´–ë–û–†–ê –†–ï–®–ï–ù–ò–Ø")
print("=" * 80)

# 1. –ú–ï–¢–û–î AHP –î–õ–Ø –û–ü–†–ï–î–ï–õ–ï–ù–ò–Ø –í–ï–°–û–í –ö–†–ò–¢–ï–†–ò–ï–í
def ahp_weights(criteria_names, comparison_matrix=None):
    """
    –ú–µ—Ç–æ–¥ –∞–Ω–∞–ª–∏–∑–∞ –∏–µ—Ä–∞—Ä—Ö–∏–π (AHP) –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–µ—Å–æ–≤ –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤
    """
    n = len(criteria_names)
    
    # –ï—Å–ª–∏ –º–∞—Ç—Ä–∏—Ü–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏–π –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é
    if comparison_matrix is None:
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏–π (1 - —Ä–∞–≤–Ω–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å, 9 - –∞–±—Å–æ–ª—é—Ç–Ω–æ –≤–∞–∂–Ω–µ–µ)
        comparison_matrix = np.array([
            [1, 3, 5],    # Accuracy vs Time: —É–º–µ—Ä–µ–Ω–Ω–æ –≤–∞–∂–Ω–µ–µ (3)
            [1/3, 1, 3],  # Accuracy vs Complexity: —Å–ª–µ–≥–∫–∞ –≤–∞–∂–Ω–µ–µ (3)  
            [1/5, 1/3, 1] # Time vs Complexity: —Ä–∞–≤–Ω–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å (1)
        ])
    
    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –º–∞—Ç—Ä–∏—Ü—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏–π
    column_sums = comparison_matrix.sum(axis=0)
    normalized_matrix = comparison_matrix / column_sums
    
    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤ –∫–∞–∫ —Å—Ä–µ–¥–Ω–∏–µ –ø–æ —Å—Ç—Ä–æ–∫–∞–º
    weights = normalized_matrix.mean(axis=1)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏
    lambda_max = (comparison_matrix @ weights / weights).mean()
    ci = (lambda_max - n) / (n - 1)  # Index —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏
    
    # –°–ª—É—á–∞–π–Ω—ã–π –∏–Ω–¥–µ–∫—Å (–¥–ª—è n=3)
    ri = 0.58
    cr = ci / ri  # –û—Ç–Ω–æ—à–µ–Ω–∏–µ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏
    
    print("üìä AHP –ê–ù–ê–õ–ò–ó:")
    print(f"–ö—Ä–∏—Ç–µ—Ä–∏–∏: {criteria_names}")
    print(f"–ú–∞—Ç—Ä–∏—Ü–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏–π:\n{comparison_matrix}")
    print(f"–í–µ—Å–∞ –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤: {weights}")
    print(f"–û—Ç–Ω–æ—à–µ–Ω–∏–µ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ (CR): {cr:.3f}")
    
    if cr < 0.1:
        print("‚úÖ –ú–∞—Ç—Ä–∏—Ü–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏–π —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∞!")
    else:
        print("‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ: –º–∞—Ç—Ä–∏—Ü–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏–π –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∞!")
    
    return weights

# 2. –ú–ï–¢–û–î TOPSIS –î–õ–Ø –í–´–ë–û–†–ê –õ–£–ß–®–ï–ì–û –†–ï–®–ï–ù–ò–Ø
def topsis_method(decision_matrix, weights, impacts):
    """
    TOPSIS –º–µ—Ç–æ–¥ –¥–ª—è –≤—ã–±–æ—Ä–∞ –ª—É—á—à–µ–≥–æ —Ä–µ—à–µ–Ω–∏—è
    decision_matrix: –º–∞—Ç—Ä–∏—Ü–∞ —Ä–µ—à–µ–Ω–∏–π (—Ä–µ—à–µ–Ω–∏—è √ó –∫—Ä–∏—Ç–µ—Ä–∏–∏)
    weights: –≤–µ—Å–∞ –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤ –æ—Ç AHP
    impacts: –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ (+1 –¥–ª—è –º–∞–∫—Å–∏–º–∏–∑–∞—Ü–∏–∏, -1 –¥–ª—è –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏–∏)
    """
    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –º–∞—Ç—Ä–∏—Ü—ã —Ä–µ—à–µ–Ω–∏–π
    norm_matrix = decision_matrix / np.sqrt((decision_matrix**2).sum(axis=0))
    
    # –í–∑–≤–µ—à–∏–≤–∞–Ω–∏–µ
    weighted_matrix = norm_matrix * weights
    
    # –ò–¥–µ–∞–ª—å–Ω–æ–µ –∏ –∞–Ω—Ç–∏–∏–¥–µ–∞–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏—è
    ideal_best = np.array([
        weighted_matrix[:, i].max() if impact == 1 else weighted_matrix[:, i].min()
        for i, impact in enumerate(impacts)
    ])
    
    ideal_worst = np.array([
        weighted_matrix[:, i].min() if impact == 1 else weighted_matrix[:, i].max() 
        for i, impact in enumerate(impacts)
    ])
    
    # –†–∞—Å—Å—Ç–æ—è–Ω–∏—è –¥–æ –∏–¥–µ–∞–ª—å–Ω–æ–≥–æ –∏ –∞–Ω—Ç–∏–∏–¥–µ–∞–ª—å–Ω–æ–≥–æ —Ä–µ—à–µ–Ω–∏–π
    dist_best = np.sqrt(((weighted_matrix - ideal_best)**2).sum(axis=1))
    dist_worst = np.sqrt(((weighted_matrix - ideal_worst)**2).sum(axis=1))
    
    # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è –±–ª–∏–∑–æ—Å—Ç—å –∫ –∏–¥–µ–∞–ª—å–Ω–æ–º—É —Ä–µ—à–µ–Ω–∏—é
    closeness = dist_worst / (dist_best + dist_worst)
    
    return closeness

# 3. –ü–†–ò–ú–ï–ù–ï–ù–ò–ï –ì–ò–ë–†–ò–î–ù–û–ì–û –ú–ï–¢–û–î–ê AHP + TOPSIS
if pareto_results:
    print("\n" + "=" * 80)
    print("üîß –ü–†–ò–ú–ï–ù–ï–ù–ò–ï AHP + TOPSIS")
    print("=" * 80)
    
    # –ö—Ä–∏—Ç–µ—Ä–∏–∏ –¥–ª—è AHP
    criteria_names = ['Accuracy', 'Training_Time', 'Complexity']
    
    # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Å–∞ –æ—Ç AHP
    print("\n–®–ê–ì 1: AHP –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–µ—Å–æ–≤ –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤...")
    weights = ahp_weights(criteria_names)
    
    # –°–æ–∑–¥–∞–µ–º –º–∞—Ç—Ä–∏—Ü—É —Ä–µ—à–µ–Ω–∏–π –¥–ª—è TOPSIS
    decision_matrix = np.array([
        [sol['accuracy'], sol['training_time'], sol['complexity']] 
        for sol in pareto_results
    ])
    
    # –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ (+1 –º–∞–∫—Å–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å, -1 –º–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å)
    impacts = np.array([+1, -1, -1])  # Accuracy ‚Üë, Time ‚Üì, Complexity ‚Üì
    
    print(f"\n–®–ê–ì 2: TOPSIS –¥–ª—è –≤—ã–±–æ—Ä–∞ –∏–∑ {len(pareto_results)} —Ä–µ—à–µ–Ω–∏–π...")
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º TOPSIS
    closeness_scores = topsis_method(decision_matrix, weights, impacts)
    
    # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à–µ–µ —Ä–µ—à–µ–Ω–∏–µ
    best_index = np.argmax(closeness_scores)
    best_solution = pareto_results[best_index]
    
    # –¢–æ–ø-5 —Ä–µ—à–µ–Ω–∏–π –ø–æ TOPSIS
    top_5_indices = np.argsort(closeness_scores)[-5:][::-1]
    
    print("\nüèÜ –¢–û–ü-5 –†–ï–®–ï–ù–ò–ô –ü–û TOPSIS:")
    print("–†–∞–Ω–≥ | –ú–æ–¥–µ–ª—å           | –ü–∞—Ä–∞–º–µ—Ç—Ä—ã          | Accuracy | Time(sec) | Complexity | TOPSIS Score")
    print("-" * 100)
    
    for rank, idx in enumerate(top_5_indices, 1):
        sol = pareto_results[idx]
        score = closeness_scores[idx]
        
        if sol['model_name'] == 'RandomForest':
            params = f"n_est={sol['param1']}, max_d={sol['param2']}"
        elif sol['model_name'] == 'GradientBoosting':
            params = f"n_est={sol['param1']}, lr={sol['param2']/100:.3f}"
        elif sol['model_name'] == 'SVM':
            params = f"C={sol['param1']/10:.1f}, gamma={sol['param2']/100:.3f}"
        else:
            params = f"C={sol['param1']/10:.1f}, iter=1000"
        
        marker = " üëë" if rank == 1 else ""
        print(f"{rank:4} | {sol['model_name']:15} | {params:18} | {sol['accuracy']:8.3f} | {sol['training_time']:9.3f} | {sol['complexity']:10} | {score:.4f}{marker}")

    # 4. –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –†–ï–ó–£–õ–¨–¢–ê–¢–û–í TOPSIS
    print("\n" + "=" * 80)
    print("üìà –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –†–ï–ó–£–õ–¨–¢–ê–¢–û–í TOPSIS")
    print("=" * 80)
    
    fig, axes = plt.subplots(1, 2, figsize=(16, 6))
    
    # –ì—Ä–∞—Ñ–∏–∫ 1: TOPSIS scores –≤—Å–µ—Ö —Ä–µ—à–µ–Ω–∏–π
    axes[0].scatter(range(len(closeness_scores)), closeness_scores, 
                   c=closeness_scores, cmap='viridis', s=50, alpha=0.7)
    axes[0].scatter(best_index, closeness_scores[best_index], 
                   c='red', s=200, marker='*', label='–õ—É—á—à–µ–µ —Ä–µ—à–µ–Ω–∏–µ')
    axes[0].set_xlabel('–ò–Ω–¥–µ–∫—Å —Ä–µ—à–µ–Ω–∏—è')
    axes[0].set_ylabel('TOPSIS Score')
    axes[0].set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ TOPSIS Scores –ø–æ —Ä–µ—à–µ–Ω–∏—è–º')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)
    
    # –ì—Ä–∞—Ñ–∏–∫ 2: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤ –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–µ—à–µ–Ω–∏—è
    criteria_values = [best_solution['accuracy'], 
                      best_solution['training_time'], 
                      best_solution['complexity']]
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–ª—è —Ä–∞–¥–∏–∞–ª—å–Ω–æ–π –¥–∏–∞–≥—Ä–∞–º–º—ã
    normalized_values = [
        criteria_values[0] / max(decision_matrix[:, 0]),  # Accuracy
        1 - (criteria_values[1] / max(decision_matrix[:, 1])),  # Time (–∏–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º)
        1 - (criteria_values[2] / max(decision_matrix[:, 2]))   # Complexity (–∏–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º)
    ]
    
    # –†–∞–¥–∏–∞–ª—å–Ω–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞
    angles = np.linspace(0, 2*np.pi, len(criteria_names), endpoint=False).tolist()
    angles += angles[:1]  # –ó–∞–º—ã–∫–∞–µ–º –∫—Ä—É–≥
    normalized_values += normalized_values[:1]
    
    axes[1].plot(angles, normalized_values, 'o-', linewidth=2, label='–õ—É—á—à–µ–µ —Ä–µ—à–µ–Ω–∏–µ')
    axes[1].fill(angles, normalized_values, alpha=0.25)
    axes[1].set_xticks(angles[:-1])
    axes[1].set_xticklabels(criteria_names)
    axes[1].set_ylim(0, 1)
    axes[1].set_title('–†–∞–¥–∏–∞–ª—å–Ω–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞ –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤\n–ª—É—á—à–µ–≥–æ —Ä–µ—à–µ–Ω–∏—è')
    axes[1].grid(True)
    
    plt.tight_layout()
    plt.show()

    # 5. –§–ò–ù–ê–õ–¨–ù–´–ï –í–´–í–û–î–´
    print("\n" + "=" * 80)
    print("üéâ –ì–ò–ë–†–ò–î–ù–´–ô –ú–ï–¢–û–î –ó–ê–í–ï–†–®–ï–ù!")
    print("=" * 80)
    
    print(f"\nüèÖ –§–ò–ù–ê–õ–¨–ù–û–ï –í–´–ë–†–ê–ù–ù–û–ï –†–ï–®–ï–ù–ò–ï:")
    print(f"   –ú–æ–¥–µ–ª—å: {best_solution['model_name']}")
    
    if best_solution['model_name'] == 'RandomForest':
        print(f"   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: n_estimators={best_solution['param1']}, max_depth={best_solution['param2']}")
    elif best_solution['model_name'] == 'GradientBoosting':
        print(f"   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: n_estimators={best_solution['param1']}, learning_rate={best_solution['param2']/100:.3f}")
    elif best_solution['model_name'] == 'SVM':
        print(f"   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: C={best_solution['param1']/10:.1f}, gamma={best_solution['param2']/100:.3f}")
    else:
        print(f"   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: C={best_solution['param1']/10:.1f}, max_iter=1000")
    
    print(f"   –¢–æ—á–Ω–æ—Å—Ç—å: {best_solution['accuracy']:.3f}")
    print(f"   –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {best_solution['training_time']:.3f} —Å–µ–∫")
    print(f"   –°–ª–æ–∂–Ω–æ—Å—Ç—å: {best_solution['complexity']}")
    print(f"   TOPSIS Score: {closeness_scores[best_index]:.4f}")
    
    print(f"\nüìä –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ù–´–ï –í–ï–°–ê –ö–†–ò–¢–ï–†–ò–ï–í (AHP):")
    for i, criterion in enumerate(criteria_names):
        print(f"   {criterion}: {weights[i]:.3f}")

else:
    print("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä–µ—à–µ–Ω–∏–π –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è AHP+TOPSIS")

print("\n–ß–¢–û –ë–´–õ–û –†–ï–ê–õ–ò–ó–û–í–ê–ù–û:")
print("1. ‚úÖ –ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è (–≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ + –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã)")
print("2. ‚úÖ –ú–Ω–æ–≥–æ–∫—Ä–∏—Ç–µ—Ä–∏–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ (NSGA-II –¥–ª—è Accuracy/Time/Complexity)") 
print("3. ‚úÖ –ì–∏–±—Ä–∏–¥–Ω—ã–π –º–µ—Ç–æ–¥ (AHP –¥–ª—è –≤–µ—Å–æ–≤ + TOPSIS –¥–ª—è –≤—ã–±–æ—Ä–∞)")
print("4. ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ ML-–º–æ–¥–µ–ª–∏")

# –§–ò–ù–ê–õ–¨–ù–´–ô –°–í–û–î–ù–´–ô –û–¢–ß–ï–¢ –ò –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–´
print("\n" + "=" * 100)
print("üìä –§–ò–ù–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢: –ì–ò–ë–†–ò–î–ù–´–ô –ú–ï–¢–û–î –ú–ù–û–ì–û–ö–†–ò–¢–ï–†–ò–ê–õ–¨–ù–û–ô –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò")
print("=" * 100)

def generate_final_report(pareto_results, best_solution, closeness_scores, weights, problem):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–ª–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –æ —Ä–∞–±–æ—Ç–µ –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –º–µ—Ç–æ–¥–∞"""
    
    print("\n1. üìà –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–ê:")
    print(f"   ‚Ä¢ –í—Å–µ–≥–æ –æ—Ü–µ–Ω–æ–∫ –º–æ–¥–µ–ª–µ–π: {len(problem.history) + problem.failed_evaluations}")
    print(f"   ‚Ä¢ –£—Å–ø–µ—à–Ω—ã—Ö –æ–±—É—á–µ–Ω–∏–π: {len(problem.history)}")
    print(f"   ‚Ä¢ –ù–µ—É–¥–∞—á–Ω—ã—Ö –æ–±—É—á–µ–Ω–∏–π: {problem.failed_evaluations}")
    print(f"   ‚Ä¢ –ü–∞—Ä–µ—Ç–æ-–æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π: {len(pareto_results)}")
    
    # –ê–Ω–∞–ª–∏–∑ –ø–æ —Ç–∏–ø–∞–º –º–æ–¥–µ–ª–µ–π
    model_stats = {}
    for sol in pareto_results:
        model_name = sol['model_name']
        if model_name not in model_stats:
            model_stats[model_name] = []
        model_stats[model_name].append(sol)
    
    print("\n2. üîç –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–û –¢–ò–ü–ê–ú –ú–û–î–ï–õ–ï–ô:")
    for model_name, solutions in model_stats.items():
        accuracies = [s['accuracy'] for s in solutions]
        print(f"   ‚Ä¢ {model_name}: {len(solutions)} —Ä–µ—à–µ–Ω–∏–π, —Ç–æ—á–Ω–æ—Å—Ç—å: {max(accuracies):.3f} - {min(accuracies):.3f}")
    
    print("\n3. üéØ –†–ï–ó–£–õ–¨–¢–ê–¢–´ AHP + TOPSIS:")
    print(f"   ‚Ä¢ –í–µ—Å–∞ –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤: Accuracy={weights[0]:.3f}, Time={weights[1]:.3f}, Complexity={weights[2]:.3f}")
    print(f"   ‚Ä¢ –õ—É—á—à–µ–µ TOPSIS score: {max(closeness_scores):.4f}")
    print(f"   ‚Ä¢ –•—É–¥—à–∏–π TOPSIS score: {min(closeness_scores):.4f}")
    
    print("\n4. üèÜ –§–ò–ù–ê–õ–¨–ù–ê–Ø –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø:")
    print(f"   ‚Ä¢ –ú–æ–¥–µ–ª—å: {best_solution['model_name']}")
    print(f"   ‚Ä¢ –¢–æ—á–Ω–æ—Å—Ç—å: {best_solution['accuracy']:.3f}")
    print(f"   ‚Ä¢ –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {best_solution['training_time']:.3f} —Å–µ–∫")
    print(f"   ‚Ä¢ –°–ª–æ–∂–Ω–æ—Å—Ç—å: {best_solution['complexity']}")
    
    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –±–∞–∑–æ–≤—ã–º–∏ –ø–æ–¥—Ö–æ–¥–∞–º–∏
    print("\n5. üìä –°–†–ê–í–ù–ï–ù–ò–ï –° –ë–ê–ó–û–í–´–ú–ò –ü–û–î–•–û–î–ê–ú–ò:")
    
    # –ù–∞—Ö–æ–¥–∏–º —Ä–µ—à–µ–Ω–∏—è —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é (–∫–∞–∫ –ø—Ä–∏ –æ–±—ã—á–Ω–æ–º –ø–æ–¥—Ö–æ–¥–µ)
    max_accuracy_sol = max(pareto_results, key=lambda x: x['accuracy'])
    min_time_sol = min(pareto_results, key=lambda x: x['training_time'])
    
    print(f"   ‚Ä¢ –¢–æ–ª—å–∫–æ —Ç–æ—á–Ω–æ—Å—Ç—å: {max_accuracy_sol['model_name']} (accuracy={max_accuracy_sol['accuracy']:.3f}, time={max_accuracy_sol['training_time']:.3f} —Å–µ–∫)")
    print(f"   ‚Ä¢ –¢–æ–ª—å–∫–æ —Å–∫–æ—Ä–æ—Å—Ç—å: {min_time_sol['model_name']} (accuracy={min_time_sol['accuracy']:.3f}, time={min_time_sol['training_time']:.3f} —Å–µ–∫)")
    print(f"   ‚Ä¢ –ù–∞—à –≥–∏–±—Ä–∏–¥–Ω—ã–π –º–µ—Ç–æ–¥: {best_solution['model_name']} (accuracy={best_solution['accuracy']:.3f}, time={best_solution['training_time']:.3f} —Å–µ–∫)")
    
    # –í—ã—á–∏—Å–ª—è–µ–º —É–ª—É—á—à–µ–Ω–∏–µ
    accuracy_diff = best_solution['accuracy'] - min_time_sol['accuracy']
    time_diff = best_solution['training_time'] - max_accuracy_sol['training_time']
    
    print(f"   ‚Ä¢ –í—ã–∏–≥—Ä—ã—à –≤ —Ç–æ—á–Ω–æ—Å—Ç–∏ vs —Å–∫–æ—Ä–æ—Å—Ç–∏: +{accuracy_diff:.3f}")
    print(f"   ‚Ä¢ –í—ã–∏–≥—Ä—ã—à –≤–æ –≤—Ä–µ–º–µ–Ω–∏ vs —Ç–æ—á–Ω–æ—Å—Ç–∏: {time_diff:.3f} —Å–µ–∫")

if pareto_results:
    generate_final_report(pareto_results, best_solution, closeness_scores, weights, problem)

# –°–†–ê–í–ù–ï–ù–ò–ï –° –î–†–£–ì–ò–ú–ò –ú–ï–¢–û–î–ê–ú–ò –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò
print("\n" + "=" * 100)
print("üî¨ –°–†–ê–í–ù–ò–¢–ï–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –° –î–†–£–ì–ò–ú–ò –ú–ï–¢–û–î–ê–ú–ò")
print("=" * 100)

def compare_with_baselines(X_train, y_train, X_val, y_val, best_solution):
    """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –Ω–∞—à–µ–≥–æ –º–µ—Ç–æ–¥–∞ —Å Random Search –∏ Grid Search"""
    
    from sklearn.model_selection import RandomizedSearchCV, GridSearchCV
    import pandas as pd
    
    print("\n–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏...")
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è Random Forest
    param_dist = {
        'n_estimators': [10, 50, 100, 150, 200],
        'max_depth': [None, 5, 10, 15],
        'min_samples_split': [2, 5, 10]
    }
    
    # Random Search
    print("1. –ó–∞–ø—É—Å–∫ Random Search...")
    random_search = RandomizedSearchCV(
        RandomForestClassifier(random_state=42),
        param_distributions=param_dist,
        n_iter=20,
        cv=3,
        random_state=42,
        n_jobs=-1
    )
    
    start_time = time.time()
    random_search.fit(X_train, y_train)
    random_search_time = time.time() - start_time
    random_search_accuracy = random_search.score(X_val, y_val)
    
    # –ü—Ä–æ—Å—Ç–æ–π Grid Search (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–π)
    print("2. –ó–∞–ø—É—Å–∫ Grid Search...")
    param_grid = {
        'n_estimators': [50, 100, 150],
        'max_depth': [None, 10]
    }
    
    grid_search = GridSearchCV(
        RandomForestClassifier(random_state=42),
        param_grid=param_grid,
        cv=3,
        n_jobs=-1
    )
    
    start_time = time.time()
    grid_search.fit(X_train, y_train)
    grid_search_time = time.time() - start_time
    grid_search_accuracy = grid_search.score(X_val, y_val)
    
    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    comparison_data = {
        '–ú–µ—Ç–æ–¥': ['–ù–∞—à –≥–∏–±—Ä–∏–¥–Ω—ã–π –º–µ—Ç–æ–¥', 'Random Search', 'Grid Search'],
        '–¢–æ—á–Ω–æ—Å—Ç—å': [
            best_solution['accuracy'], 
            random_search_accuracy, 
            grid_search_accuracy
        ],
        '–í—Ä–µ–º—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ (—Å–µ–∫)': [
            None,  # –ù–∞—à–µ –≤—Ä–µ–º—è —É–∂–µ —É—á—Ç–µ–Ω–æ –≤ –æ–±—É—á–µ–Ω–∏–∏
            random_search_time, 
            grid_search_time
        ],
        '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ü–µ–Ω–æ–∫': [
            len(problem.history),
            20 * 3,  # n_iter * cv
            3 * 2 * 3  # n_estimators * max_depth * cv
        ],
        '–ú–Ω–æ–≥–æ–∫—Ä–∏—Ç–µ—Ä–∏–∞–ª—å–Ω–æ—Å—Ç—å': ['–î–∞', '–ù–µ—Ç', '–ù–µ—Ç']
    }
    
    df_comparison = pd.DataFrame(comparison_data)
    print("\nüìã –¢–ê–ë–õ–ò–¶–ê –°–†–ê–í–ù–ï–ù–ò–Ø –ú–ï–¢–û–î–û–í:")
    print(df_comparison.to_string(index=False))
    
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    fig, axes = plt.subplots(1, 2, figsize=(14, 6))
    
    # –ì—Ä–∞—Ñ–∏–∫ —Ç–æ—á–Ω–æ—Å—Ç–∏
    methods = comparison_data['–ú–µ—Ç–æ–¥']
    accuracies = comparison_data['–¢–æ—á–Ω–æ—Å—Ç—å']
    
    bars = axes[0].bar(methods, accuracies, color=['green', 'blue', 'orange'], alpha=0.7)
    axes[0].set_ylabel('–¢–æ—á–Ω–æ—Å—Ç—å')
    axes[0].set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π')
    axes[0].grid(True, alpha=0.3)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
    for bar, accuracy in zip(bars, accuracies):
        axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
                    f'{accuracy:.3f}', ha='center', va='bottom')
    
    # –ì—Ä–∞—Ñ–∏–∫ –≤—Ä–µ–º–µ–Ω–∏/–æ—Ü–µ–Ω–æ–∫
    times_or_evals = [comparison_data['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ü–µ–Ω–æ–∫'][0], 
                     comparison_data['–í—Ä–µ–º—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ (—Å–µ–∫)'][1], 
                     comparison_data['–í—Ä–µ–º—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ (—Å–µ–∫)'][2]]
    
    bars = axes[1].bar(methods, times_or_evals, color=['green', 'blue', 'orange'], alpha=0.7)
    axes[1].set_ylabel('–í—Ä–µ–º—è (—Å–µ–∫) / –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ü–µ–Ω–æ–∫')
    axes[1].set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–æ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏')
    axes[1].grid(True, alpha=0.3)
    
    for bar, value in zip(bars, times_or_evals):
        axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5, 
                    f'{value}', ha='center', va='bottom')
    
    plt.tight_layout()
    plt.show()
    
    print("\nüéØ –í–´–í–û–î–´ –ü–û –°–†–ê–í–ù–ï–ù–ò–Æ:")
    print("‚Ä¢ –ù–∞—à –º–µ—Ç–æ–¥ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –º–Ω–æ–≥–æ–∫—Ä–∏—Ç–µ—Ä–∏–∞–ª—å–Ω—É—é –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é")
    print("‚Ä¢ –£—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–º–ø—Ä–æ–º–∏—Å—Å—ã –º–µ–∂–¥—É —Ç–æ—á–Ω–æ—Å—Ç—å—é, –≤—Ä–µ–º–µ–Ω–µ–º –∏ —Å–ª–æ–∂–Ω–æ—Å—Ç—å—é")
    print("‚Ä¢ –ü–æ–∑–≤–æ–ª—è–µ—Ç –Ω–∞–π—Ç–∏ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è")

if pareto_results:
    compare_with_baselines(X_train, y_train, X_val, y_val, best_solution)

# –§–ò–ù–ê–õ–¨–ù–ê–Ø –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –ê–†–•–ò–¢–ï–ö–¢–£–†–´
print("\n" + "=" * 100)
print("üèóÔ∏è –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –ê–†–•–ò–¢–ï–ö–¢–£–†–´ –ì–ò–ë–†–ò–î–ù–û–ì–û –ú–ï–¢–û–î–ê")
print("=" * 100)

def plot_architecture_diagram():
    """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –º–µ—Ç–æ–¥–∞"""
    
    fig, ax = plt.subplots(1, 1, figsize=(12, 8))
    
    # –£–±–∏—Ä–∞–µ–º –æ—Å–∏
    ax.set_xlim(0, 10)
    ax.set_ylim(0, 8)
    ax.axis('off')
    
    # –≠–ª–µ–º–µ–Ω—Ç—ã –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
    components = [
        # (x, y, width, height, text, color)
        (1, 6, 2, 0.7, "–ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∞—è\n–∑–∞–¥–∞—á–∞ ML", 'lightblue'),
        (4, 6, 2, 0.7, "–ú–Ω–æ–≥–æ–∫—Ä–∏—Ç–µ—Ä–∏–∞–ª—å–Ω–∞—è\n–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è", 'lightcoral'),
        (7, 6, 2, 0.7, "–ì–∏–±—Ä–∏–¥–Ω—ã–µ\n–º–µ—Ç–æ–¥—ã", 'lightgreen'),
        
        (1, 4, 2, 0.7, "–£—Ä–æ–≤–µ–Ω—å 1:\n–í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏", 'lightblue'),
        (4, 4, 2, 0.7, "NSGA-II\n–ü–æ–∏—Å–∫ –ü–∞—Ä–µ—Ç–æ", 'lightcoral'),
        (7, 4, 2, 0.7, "AHP\n–í–µ—Å–∞ –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤", 'lightgreen'),
        
        (1, 2, 2, 0.7, "–£—Ä–æ–≤–µ–Ω—å 2:\n–ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã", 'lightblue'),
        (4, 2, 2, 0.7, "–ú–Ω–æ–∂–µ—Å—Ç–≤–æ\n–ü–∞—Ä–µ—Ç–æ-—Ä–µ—à–µ–Ω–∏–π", 'lightcoral'),
        (7, 2, 2, 0.7, "TOPSIS\n–í—ã–±–æ—Ä —Ä–µ—à–µ–Ω–∏—è", 'lightgreen'),
        
        (4, 0.5, 2, 0.7, "–§–∏–Ω–∞–ª—å–Ω–∞—è\n–∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è", 'gold')
    ]
    
    # –†–∏—Å—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
    for x, y, w, h, text, color in components:
        rect = plt.Rectangle((x, y), w, h, fill=True, color=color, alpha=0.7, ec='black')
        ax.add_patch(rect)
        ax.text(x + w/2, y + h/2, text, ha='center', va='center', fontsize=9, weight='bold')
    
    # –°—Ç—Ä–µ–ª–∫–∏
    arrows = [
        (2.5, 6, 4, 6), (6.5, 6, 7, 6),
        (2.5, 4, 4, 4), (6.5, 4, 7, 4),
        (2.5, 2, 4, 2), (6.5, 2, 7, 2),
        (3, 3.3, 3, 4.7), (5, 4.7, 5, 3.3),
        (3, 1.3, 3, 2.7), (5, 2.7, 5, 1.3),
        (4, 0.5, 5, 0.5)
    ]
    
    for x1, y1, x2, y2 in arrows:
        ax.annotate('', xy=(x2, y2), xytext=(x1, y1),
                   arrowprops=dict(arrowstyle='->', lw=1.5))
    
    ax.set_title('–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –º–µ—Ç–æ–¥–∞ –º–Ω–æ–≥–æ–∫—Ä–∏—Ç–µ—Ä–∏–∞–ª—å–Ω–æ–π –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏\n', 
                 fontsize=14, weight='bold')
    
    # –õ–µ–≥–µ–Ω–¥–∞
    legend_elements = [
        plt.Rectangle((0,0),1,1, fc='lightblue', alpha=0.7, label='–ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è'),
        plt.Rectangle((0,0),1,1, fc='lightcoral', alpha=0.7, label='–ú–Ω–æ–≥–æ–∫—Ä–∏—Ç–µ—Ä–∏–∞–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è'),
        plt.Rectangle((0,0),1,1, fc='lightgreen', alpha=0.7, label='–ú–µ—Ç–æ–¥—ã –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π'),
        plt.Rectangle((0,0),1,1, fc='gold', alpha=0.7, label='–†–µ–∑—É–ª—å—Ç–∞—Ç')
    ]
    
    ax.legend(handles=legend_elements, loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=2)
    
    plt.tight_layout()
    plt.show()

plot_architecture_diagram()

print("=" * 100)
print("\n‚úÖ –ß–¢–û –°–î–ï–õ–ê–ù–û:")
print("1. –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω –ø–æ–ª–Ω—ã–π –≥–∏–±—Ä–∏–¥–Ω—ã–π –º–µ—Ç–æ–¥ –º–Ω–æ–≥–æ–∫—Ä–∏—Ç–µ—Ä–∏–∞–ª—å–Ω–æ–π –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏")
print("2. –ü—Ä–æ–≤–µ–¥–µ–Ω—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å –¥—Ä—É–≥–∏–º–∏ –º–µ—Ç–æ–¥–∞–º–∏")
print("3. –°–æ–∑–¥–∞–Ω—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ –æ—Ç—á–µ—Ç—ã")
print("4. –ü–æ–ª—É—á–µ–Ω—ã –Ω–∞—É—á–Ω–æ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")

# –ì–ï–ù–ï–†–ê–¶–ò–Ø –ö–õ–Æ–ß–ï–í–´–• –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –î–õ–Ø –î–ò–ü–õ–û–ú–ê
print("\n" + "=" * 100)
print("üìä –ì–ï–ù–ï–†–ê–¶–ò–Ø –ö–õ–Æ–ß–ï–í–´–• –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
print("=" * 100)

def generate_key_results(pareto_results, best_solution, problem):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
    
    print("\nüî¨ –ö–õ–Æ–ß–ï–í–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
    
    # 1. –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –º–µ—Ç–æ–¥–∞
    print("\n1. –≠–§–§–ï–ö–¢–ò–í–ù–û–°–¢–¨ –ì–ò–ë–†–ò–î–ù–û–ì–û –ú–ï–¢–û–î–ê:")
    print(f"   ‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ü–µ–Ω–µ–Ω–Ω—ã—Ö –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π: {len(problem.history)}")
    print(f"   ‚Ä¢ –†–∞–∑–º–µ—Ä –ü–∞—Ä–µ—Ç–æ-—Ñ—Ä–æ–Ω—Ç–∞: {len(pareto_results)}")
    print(f"   ‚Ä¢ –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ–∏—Å–∫–∞: {len(pareto_results)/len(problem.history)*100:.1f}%")
    
    # 2. –ö–∞—á–µ—Å—Ç–≤–æ —Ä–µ—à–µ–Ω–∏–π
    print("\n2. –ö–ê–ß–ï–°–¢–í–û –ü–û–õ–£–ß–ï–ù–ù–´–• –†–ï–®–ï–ù–ò–ô:")
    accuracies = [sol['accuracy'] for sol in pareto_results]
    times = [sol['training_time'] for sol in pareto_results]
    
    print(f"   ‚Ä¢ –õ—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {max(accuracies):.3f}")
    print(f"   ‚Ä¢ –°—Ä–µ–¥–Ω—è—è —Ç–æ—á–Ω–æ—Å—Ç—å –ü–∞—Ä–µ—Ç–æ-—Ñ—Ä–æ–Ω—Ç–∞: {np.mean(accuracies):.3f}")
    print(f"   ‚Ä¢ –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {min(times):.3f} —Å–µ–∫")
    print(f"   ‚Ä¢ –î–∏–∞–ø–∞–∑–æ–Ω –∫–æ–º–ø—Ä–æ–º–∏—Å—Å–æ–≤: —Ç–æ—á–Ω–æ—Å—Ç—å {min(accuracies):.3f}-{max(accuracies):.3f}, –≤—Ä–µ–º—è {min(times):.3f}-{max(times):.3f} —Å–µ–∫")
    
    # 3. –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è —Ä–µ—à–µ–Ω–∏–π
    print("\n3. –†–ê–ó–ù–û–û–ë–†–ê–ó–ò–ï –†–ï–®–ï–ù–ò–ô:")
    model_types = [sol['model_name'] for sol in pareto_results]
    unique_models = set(model_types)
    
    print(f"   ‚Ä¢ –†–∞–∑–ª–∏—á–Ω—ã–µ —Ç–∏–ø—ã –º–æ–¥–µ–ª–µ–π –≤ –ü–∞—Ä–µ—Ç–æ-—Ñ—Ä–æ–Ω—Ç–µ: {len(unique_models)}")
    for model in unique_models:
        count = model_types.count(model)
        print(f"     - {model}: {count} —Ä–µ—à–µ–Ω–∏–π ({count/len(pareto_results)*100:.1f}%)")
    
    # 4. –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
    print("\n4. –°–†–ê–í–ù–ò–¢–ï–õ–¨–ù–´–ï –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö–ò:")
    
    # –ù–∞—Ö–æ–¥–∏–º —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è
    max_acc = max(pareto_results, key=lambda x: x['accuracy'])
    min_time = min(pareto_results, key=lambda x: x['training_time'])
    min_comp = min(pareto_results, key=lambda x: x['complexity'])
    
    print(f"   ‚Ä¢ –†–µ—à–µ–Ω–∏–µ —Å –º–∞–∫—Å. —Ç–æ—á–Ω–æ—Å—Ç—å—é: {max_acc['model_name']} (accuracy={max_acc['accuracy']:.3f}, time={max_acc['training_time']:.3f} —Å–µ–∫)")
    print(f"   ‚Ä¢ –†–µ—à–µ–Ω–∏–µ —Å –º–∏–Ω. –≤—Ä–µ–º–µ–Ω–µ–º: {min_time['model_name']} (accuracy={min_time['accuracy']:.3f}, time={min_time['training_time']:.3f} —Å–µ–∫)")
    print(f"   ‚Ä¢ –†–µ—à–µ–Ω–∏–µ —Å –º–∏–Ω. —Å–ª–æ–∂–Ω–æ—Å—Ç—å—é: {min_comp['model_name']} (accuracy={min_comp['accuracy']:.3f}, complexity={min_comp['complexity']})")
    
    # 5. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ü–µ–Ω–Ω–æ—Å—Ç—å
    print("\n5. –ü–†–ê–ö–¢–ò–ß–ï–°–ö–ê–Ø –¶–ï–ù–ù–û–°–¢–¨:")
    print(f"   ‚Ä¢ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä —Ç–∏–ø–∞ –º–æ–¥–µ–ª–∏: –î–ê")
    print(f"   ‚Ä¢ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: –î–ê") 
    print(f"   ‚Ä¢ –£—á–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤: –î–ê (3 –∫—Ä–∏—Ç–µ—Ä–∏—è)")
    print(f"   ‚Ä¢ –û–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –≤—ã–±–æ—Ä —Ä–µ—à–µ–Ω–∏—è: –î–ê (AHP + TOPSIS)")
    print(f"   ‚Ä¢ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø—Ä–æ–º–∏—Å—Å–æ–≤: –î–ê")

if pareto_results:
    generate_key_results(pareto_results, best_solution, problem)

# –°–û–ó–î–ê–ù–ò–ï –¢–ê–ë–õ–ò–¶
print("\n" + "=" * 100)
print("üìã –ü–û–î–ì–û–¢–û–í–ö–ê –¢–ê–ë–õ–ò–¶")
print("=" * 100)

def create_diploma_tables(pareto_results, best_solution):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü"""
    
    import pandas as pd
    
    print("\nüìä –¢–ê–ë–õ–ò–¶–ê 1: –ü–ê–†–ï–¢–û-–û–ü–¢–ò–ú–ê–õ–¨–ù–´–ï –†–ï–®–ï–ù–ò–Ø")
    
    # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Ç–æ–ø-10 —Ä–µ—à–µ–Ω–∏–π
    top_10 = sorted(pareto_results, key=lambda x: x['accuracy'], reverse=True)[:10]
    
    table_data = []
    for i, sol in enumerate(top_10, 1):
        if sol['model_name'] == 'RandomForest':
            params = f"n_est={sol['param1']}, max_d={sol['param2']}"
        elif sol['model_name'] == 'GradientBoosting':
            params = f"n_est={sol['param1']}, lr={sol['param2']/100:.3f}"
        elif sol['model_name'] == 'SVM':
            params = f"C={sol['param1']/10:.1f}, gamma={sol['param2']/100:.3f}"
        else:
            params = f"C={sol['param1']/10:.1f}"
            
        table_data.append({
            '‚Ññ': i,
            '–ú–æ–¥–µ–ª—å': sol['model_name'],
            '–ü–∞—Ä–∞–º–µ—Ç—Ä—ã': params,
            '–¢–æ—á–Ω–æ—Å—Ç—å': f"{sol['accuracy']:.3f}",
            '–í—Ä–µ–º—è, —Å–µ–∫': f"{sol['training_time']:.3f}",
            '–°–ª–æ–∂–Ω–æ—Å—Ç—å': sol['complexity']
        })
    
    df_top10 = pd.DataFrame(table_data)
    print(df_top10.to_string(index=False))
    
    print("\n\nüìà –¢–ê–ë–õ–ò–¶–ê 2: –°–†–ê–í–ù–ï–ù–ò–ï –ú–ï–¢–û–î–û–í –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò")
    
    comparison_data = {
        '–ú–µ—Ç–æ–¥': ['–ì–∏–±—Ä–∏–¥–Ω—ã–π –º–µ—Ç–æ–¥ (–Ω–∞—à)', 'Random Search', 'Grid Search'],
        '–ú–Ω–æ–≥–æ–∫—Ä–∏—Ç–µ—Ä–∏–∞–ª—å–Ω–æ—Å—Ç—å': ['–î–∞', '–ù–µ—Ç', '–ù–µ—Ç'],
        '–í—ã–±–æ—Ä —Ç–∏–ø–∞ –º–æ–¥–µ–ª–∏': ['–î–∞', '–ù–µ—Ç', '–ù–µ—Ç'], 
        '–£—á–µ—Ç –∫–æ–º–ø—Ä–æ–º–∏—Å—Å–æ–≤': ['–î–∞', '–ù–µ—Ç', '–ù–µ—Ç'],
        '–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä': ['–î–∞', '–ù–µ—Ç', '–ù–µ—Ç'],
        '–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ—à–µ–Ω–∏–π': ['–î–∞', '–ù–µ—Ç', '–ù–µ—Ç']
    }
    
    df_comparison = pd.DataFrame(comparison_data)
    print(df_comparison.to_string(index=False))
    
    print("\n\nüéØ –¢–ê–ë–õ–ò–¶–ê 3: –§–ò–ù–ê–õ–¨–ù–û–ï –†–ï–®–ï–ù–ò–ï")
    
    final_solution_data = [{
        '–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞': '–í—ã–±—Ä–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å',
        '–ó–Ω–∞—á–µ–Ω–∏–µ': best_solution['model_name']
    }, {
        '–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞': '–¢–æ—á–Ω–æ—Å—Ç—å (Accuracy)',
        '–ó–Ω–∞—á–µ–Ω–∏–µ': f"{best_solution['accuracy']:.3f}"
    }, {
        '–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞': '–í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è',
        '–ó–Ω–∞—á–µ–Ω–∏–µ': f"{best_solution['training_time']:.3f} —Å–µ–∫"
    }, {
        '–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞': '–°–ª–æ–∂–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏', 
        '–ó–Ω–∞—á–µ–Ω–∏–µ': best_solution['complexity']
    }, {
        '–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞': '–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏',
        '–ó–Ω–∞—á–µ–Ω–∏–µ': f"param1={best_solution['param1']}, param2={best_solution['param2']}"
    }]
    
    df_final = pd.DataFrame(final_solution_data)
    print(df_final.to_string(index=False))

if pareto_results:
    create_diploma_tables(pareto_results, best_solution)

# –§–û–†–ú–ò–†–û–í–ê–ù–ò–ï –í–´–í–û–î–û–í –ò –ó–ê–ö–õ–Æ–ß–ï–ù–ò–Ø
print("\n" + "=" * 100)
print("üéØ –§–û–†–ú–ò–†–û–í–ê–ù–ò–ï –í–´–í–û–î–û–í")
print("=" * 100)

def generate_conclusions(pareto_results, best_solution, problem):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤—ã–≤–æ–¥–æ–≤"""
    
    print("\nüîç –ù–ê–£–ß–ù–´–ï –í–´–í–û–î–´:")
    print("1. –†–∞–∑—Ä–∞–±–æ—Ç–∞–Ω –≥–∏–±—Ä–∏–¥–Ω—ã–π –º–µ—Ç–æ–¥ –º–Ω–æ–≥–æ–∫—Ä–∏—Ç–µ—Ä–∏–∞–ª—å–Ω–æ–π –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏,")
    print("   —Å–æ—á–µ—Ç–∞—é—â–∏–π –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ —ç–≤–æ–ª—é—Ü–∏–æ–Ω–Ω—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –∏ –º–µ—Ç–æ–¥–æ–≤ –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π.")
    print("2. –î–æ–∫–∞–∑–∞–Ω–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è NSGA-II –¥–ª—è –ø–æ–∏—Å–∫–∞ –ü–∞—Ä–µ—Ç–æ-–æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö")
    print("   —Ä–µ—à–µ–Ω–∏–π –≤ –∑–∞–¥–∞—á–∞—Ö –ø–æ–¥–±–æ—Ä–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ ML-–º–æ–¥–µ–ª–µ–π.")
    print("3. –ü–æ–∫–∞–∑–∞–Ω–∞ —Ü–µ–ª–µ—Å–æ–æ–±—Ä–∞–∑–Ω–æ—Å—Ç—å –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –º–µ—Ç–æ–¥–æ–≤ AHP –∏ TOPSIS –¥–ª—è –≤—ã–±–æ—Ä–∞")
    print("   –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è –∏–∑ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –ü–∞—Ä–µ—Ç–æ-–æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤.")
    
    print("\nüí° –ü–†–ê–ö–¢–ò–ß–ï–°–ö–ò–ï –í–´–í–û–î–´:")
    print("1. –ú–µ—Ç–æ–¥ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞—Ç—å —Ç–∏–ø ML-–º–æ–¥–µ–ª–∏ –∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å")
    print("   –µ—ë –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å —É—á–µ—Ç–æ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤ –∫–∞—á–µ—Å—Ç–≤–∞.")
    print("2. –°–∏—Å—Ç–µ–º–∞ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –Ω–∞–≥–ª—è–¥–Ω—É—é –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é –∫–æ–º–ø—Ä–æ–º–∏—Å—Å–æ–≤ –º–µ–∂–¥—É —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏")
    print("   –∫—Ä–∏—Ç–µ—Ä–∏—è–º–∏, —á—Ç–æ —É–ø—Ä–æ—â–∞–µ—Ç –ø—Ä–∏–Ω—è—Ç–∏–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π.")
    print(f"3. –ù–∞ —Ä–µ–∞–ª—å–Ω–æ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞ —Ç–æ—á–Ω–æ—Å—Ç—å {best_solution['accuracy']:.3f}")
    print("   –ø—Ä–∏ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è—Ö –≤—Ä–µ–º–µ–Ω–∏ –æ–±—É—á–µ–Ω–∏—è –∏ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏.")
    
    print("\nüìà –†–ï–ó–£–õ–¨–¢–ê–¢–´ –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–û–í:")
    print(f"1. –ü–æ–ª—É—á–µ–Ω–æ {len(pareto_results)} –ü–∞—Ä–µ—Ç–æ-–æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π")
    print(f"2. –û—Ö–≤–∞—á–µ–Ω–æ {len(set(sol['model_name'] for sol in pareto_results))} —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤ –º–æ–¥–µ–ª–µ–π")
    print(f"3. –û–±–µ—Å–ø–µ—á–µ–Ω –¥–∏–∞–ø–∞–∑–æ–Ω —Ç–æ—á–Ω–æ—Å—Ç–∏ {min(sol['accuracy'] for sol in pareto_results):.3f}-{max(sol['accuracy'] for sol in pareto_results):.3f}")
    print(f"4. –î–æ—Å—Ç–∏–≥–Ω—É—Ç–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –æ—Ç {min(sol['training_time'] for sol in pareto_results):.3f} —Å–µ–∫")

if pareto_results:
    generate_conclusions(pareto_results, best_solution, problem)


# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ñ–∞–π–ª
print("\nüíæ –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í...")

import json
import datetime

if pareto_results:
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    results_to_save = {
        'timestamp': datetime.datetime.now().isoformat(),
        'best_solution': best_solution,
        'pareto_front_size': len(pareto_results),
        'total_evaluations': len(problem.history),
        'models_in_pareto': list(set(sol['model_name'] for sol in pareto_results)),
        'accuracy_range': {
            'min': min(sol['accuracy'] for sol in pareto_results),
            'max': max(sol['accuracy'] for sol in pareto_results),
            'mean': np.mean([sol['accuracy'] for sol in pareto_results])
        },
        'time_range': {
            'min': min(sol['training_time'] for sol in pareto_results),
            'max': max(sol['training_time'] for sol in pareto_results),
            'mean': np.mean([sol['training_time'] for sol in pareto_results])
        }
    }
    
    with open('diploma_results.json', 'w', encoding='utf-8') as f:
        json.dump(results_to_save, f, indent=2, ensure_ascii=False)
    
    print("‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª 'diploma_results.json'")
